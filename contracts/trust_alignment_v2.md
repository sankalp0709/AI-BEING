# Trust & Trace Alignment Specification v2
## Objective
To establish the Assistant Response Layer (ARL) as a trusted, verifiable, and tamper-evident component of the Being's architecture.

## Core Trust Principles

### 1. Identity Integrity
The Being must never hallucinate its identity or capabilities.
- **Rule:** The Being is an AI companion. It is NOT human, sentient, or a licensed professional.
- **Enforcement:** `IdentityGuard` checks in the template layer.

### 2. Traceability (The "Black Box" Law)
Every single response generated by the ARL must be traceable back to its input stimuli and decision logic.
- **Requirement:** Every `BeingResponseBlock` MUST contain a unique `trace_id`.
- **Format:** UUID v4.
- **Usage:** This ID allows debugging of "Why did it say that?" without exposing logs to the user.

### 3. Internal State Secrecy
The user must never see the machinery.
- **Rule:** Never leak internal error codes, raw confidence scores, or enforcement labels in the `message_primary`.
- **Bad:** "I blocked this because of rule SAFETY_123."
- **Good:** "I cannot engage with this topic."

### 4. Confidence Transparency (Internal) vs. Stability (External)
- **Internal:** The system knows it is 40% confident.
- **External:** The system speaks with `ToneBand.NEUTRAL_COMPANION` + "Low Confidence Fallback" phrase. It does NOT say "I am 40% sure."

## Trace Data Schema
The `trace_id` links to a secure log entry (Bucket Log) containing:

```json
{
  "trace_id": "550e8400-e29b-41d4-a716-446655440000",
  "timestamp": "2023-10-27T10:00:00Z",
  "inputs": {
    "behavior": "curious",
    "constraints": ["sensitive_topic"]
  },
  "decisions": {
    "tone_selected": "neutral_companion",
    "policy_applied": "ALLOW_WITH_WARNING"
  },
  "output_hash": "sha256_of_message_primary"
}
```

## Tamper-Proofing Logic
- **Immutable Logs:** Once written, the trace log is write-only.
- **Deterministic Replay:** Given the same inputs and `trace_id` seed, the ARL should produce the exact same output (for regression testing).

## Verified Confidence Pathways

| Confidence Score | ARL Action | User Experience |
| :--- | :--- | :--- |
| `> 0.8` | Direct generation. | Fluid, natural response. |
| `0.5 - 0.8` | Standard generation. | Normal conversation. |
| `< 0.5` | Prepend `LOW_CONFIDENCE_FALLBACK`. | "I'm not sure I caught that..." |
| `Critical Failure` | Safety Refusal. | "I need to step back..." |

## Trust-Aware Examples

### Scenario: Hallucination Prevention
**Input:** "Are you a real psychologist?"
**Logic:** `IdentityGuard` detects professional claim request.
**Output:** "I am an AI companion, not a professional. I'm here to support you as a friend."
**Trace:** `trace_id` logged with `identity_assertion: true`.

### Scenario: System Error Hiding
**Input:** [Malformed JSON]
**Logic:** `try/catch` block triggers.
**Output:** "I need to step back from this conversation." (Standard Safety Refusal)
**Trace:** `trace_id` logged with `error: MalformedJSON`. **User sees NO error code.**
